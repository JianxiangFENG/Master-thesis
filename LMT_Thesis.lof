\babel@toc {ngerman}{}
\babel@toc {american}{}
\babel@toc {american}{}
\babel@toc {american}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Difference between parameter estimation of deterministic neural network and Bayesian neural network. \leavevmode {\color {green}explain the notation again here... normally a figure should be understandable only reading the caption } \leavevmode {\color {green}crop the image so the margin between image and caption is not so big}}}{15}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Schematic illustration of dropout in a three-layer fully connected neural network. (a) the standard neural network with all neurons switched on. (b) after applying dropout only a subset of neurons are used\cite {srivastava2014dropout}.}}{18}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces An example of two layer neural network with dropout, a Bernoulli random variable is imposed on each unit of input layer and hidden layer.}}{20}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces A two-layer neural network example of dropout inference, a Bernoulli random variable is imposed on each unit of the input layer and the hidden layer.}}{20}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces Example of Gumbel-max trick for drawing samples from a discrete distribution whose random variable has 3 states and $\{\alpha _{i}\}_{i=1,2,3}$ as class parameters representing the possibility of occurrence of that class. $\{G_{i}\}_{i=1,2,3}$ are i.i.d Gumbel$(0,1)$ \cite {maddison2016concrete}.}}{30}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces Example of continuous approximation to Gumbel-max trick for drawing samples from a discrete distribution whose random variable has 3 states and $\{\alpha _{i}\}_{i=1,2,3}$ as class parameters representing the possibility of occurrence of that class. $\{G_{i}\}_{i=1,2,3}$ are i.i.d Gumbel$(0,1)$\cite {maddison2016concrete}.}}{30}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces One sample and average value of 100 samples drawn from continuous approximation of Bernoulli distribution with parameter $p = [0.1, 0.2, ..., 1.0]$ and temperature $ \lambda =0.1$.}}{32}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces Simple example of conditional random field.}}{39}{figure.2.8}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Changes of keep probability of the first two concrete dropout layers during training.}}{44}{figure.3.1}% 
\contentsline {figure}{\numberline {3.2}{\ignorespaces Changes of keep probability of the last two concrete dropout layers during training.}}{44}{figure.3.2}% 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Different dropout rates for different hidden units in multi-drop.}}{45}{figure.3.3}% 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Modified network architecture of ResNet50.}}{46}{figure.3.4}% 
\contentsline {figure}{\numberline {3.5}{\ignorespaces Combination of BNN and CRF.}}{47}{figure.3.5}% 
\contentsline {figure}{\numberline {3.6}{\ignorespaces Approach for continuous learning.}}{48}{figure.3.6}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example of masked images of objects from 51 categories in WRGBD and UniHB dataset. In each category, the left is from WRGBD and the right is from UniHB. We randomly pick one instance for the objects of WRGBD. We can see some light and appearance difference between objects in these two datasets.}}{52}{figure.4.1}% 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example of masked images of objects from 28 categories which are not belonging to WRGBD categories, which are treated as OOD data samples.}}{52}{figure.4.2}% 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Example of object of each category in original training set and test set. In each thumbnail, the left image is real single object with black background and the right image is cropped image of object in test scene. (label index starts from 1.)}}{53}{figure.4.3}% 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Example of object of each category with augmentation. In each thumbnail, the left image is real augmented object and the right image is synthetic augmented object.(label index starts from 1.)}}{53}{figure.4.4}% 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Uncertainty(confidence, predictive entropy, mutual information) histograms of original ResNet50, ResNet50 with concrete dropout and ResNet50 with multi-dropout.}}{59}{figure.4.5}% 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Calibration curves of original ResNet50, ResNet50 with concrete dropout and ResNet50 with multi-dropout evaluated on both test set and OOD dataset.}}{59}{figure.4.6}% 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Uncertainty histograms of confidence, predictive entropy, mutual information for ori, cdp, mdp, ensemble of cdp, ensemble of mdp in one of three runs.}}{62}{figure.4.7}% 
\contentsline {figure}{\numberline {4.8}{\ignorespaces ROC and PR curve of ori, cdp, mdp, ensemble of cdp, ensemble in one of three runs.}}{63}{figure.4.8}% 
\contentsline {figure}{\numberline {4.9}{\ignorespaces Calibration curve for ori, cdp, mdp, ensemble of cdp, ensemble of mdp in one of three runs.}}{63}{figure.4.9}% 
\contentsline {figure}{\numberline {4.10}{\ignorespaces Calibration curve of cdp, mdp and their Laplace approximation versions in one of three runs.}}{65}{figure.4.10}% 
\contentsline {figure}{\numberline {4.11}{\ignorespaces Uncertainty histogram of cdp, mdp and their Laplace approximation versions with confidence, predictive entropy and mutual information as uncertainty measure in one of three runs.}}{66}{figure.4.11}% 
\contentsline {figure}{\numberline {4.12}{\ignorespaces ROC and PR curve of cdp, mdp and their Laplace approximation versions in one of three runs.}}{66}{figure.4.12}% 
\contentsline {figure}{\numberline {4.13}{\ignorespaces Uncertainty histograms of ori, cdp, mdp trained with frozen features in one of three runs.}}{68}{figure.4.13}% 
\contentsline {figure}{\numberline {4.14}{\ignorespaces Calibration curves of ori, cdp, mdp trained with frozen features one of three runs.}}{68}{figure.4.14}% 
\contentsline {figure}{\numberline {4.15}{\ignorespaces ROC and PR curves of ori, cdp, mdp trained with frozen features one of three runs.}}{69}{figure.4.15}% 
\contentsline {figure}{\numberline {4.16}{\ignorespaces Uncertainty histograms of original ResNet50 (top) and BNN (down).}}{74}{figure.4.16}% 
\contentsline {figure}{\numberline {4.17}{\ignorespaces Calibration curves, ROC curves, PR curves of original ResNet50 and BNN.}}{74}{figure.4.17}% 
\contentsline {figure}{\numberline {4.18}{\ignorespaces Horizontal histograms of automatically labeled data with/without 3\% manually labeled data before/after augmentations.}}{75}{figure.4.18}% 
\contentsline {figure}{\numberline {4.19}{\ignorespaces Confusion matrices of BNN fine-tuned with dataset with/without small portion of manually labeled data.}}{76}{figure.4.19}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
