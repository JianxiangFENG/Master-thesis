\switchlanguage{en} % The abstract is supposed to be in English!

\thispagestyle{plain}

\section*{Abstract}
Deep learning based classifiers have achieved tremendous success on different tasks. However, this kind of classifier cannot provide reliable uncertainty estimation about their predictions and express excessive overconfidence, which means that the models are highly certain although they are not familiar with the related input. This behavior can easily lead to severe consequences in safety-critical applications such as diagnosis of diseases, perception of self-driving car and so on. Especially in the case of the deployment of robots, the robots should be aware of the correctness of the predictions they make, so that they are able to avoid unnecessary accidents and adapt itself in an unfamiliar environment. Besides uncertainty for independent data examples, uncertainty related to dependencies between data examples should be taken into account. When recognizing objects with similar appearances but different contexts in a specific scene, the classifier should express reliably high uncertainty about its predictions because of appearance ambiguities. At the same time, contextual information should be handled properly and utilized to resolve this kind of ambiguities, aiming to further improve the performance. 

In this work, Bayesian neural networks with different inference techniques such as dropout variational inference and scalable Laplace approximation are employed to improve the uncertainty estimation. With a reliable uncertainty estimation, a classifier trained on an easily obtainable dataset should be able to adapt itself in a test environment by collecting dataset for fine-tuning with as little manual efforts as possible. Additionally, a conditional random field is employed to further improve the performance by utilizing more information brought by better uncertainty estimation and handling the contextual information between objects properly. Extensive experiments are performed to show that uncertainty estimation can be improved with Bayesian neural networks in terms of different evaluation metrics. Besides, it is demonstrated that manual efforts in collecting dataset for fine-tuning a classifier can be reduced with the help of improved uncertainty estimation on experiments with two different datasets. Last but not least, experiments also show that the conditional random field is able to further improve the performance by making use of better uncertainty estimation and contextual information.

\switchlanguage{\lang} % Switch back to the document's default language.
