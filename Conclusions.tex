\chapter{Summary and Conclusion}
\section{Summary}
In this work, different approaches for the improvement of a classification system related to uncertainty are investigated.
 
Firstly, in order to enable a classifier to adapt itself to a test environment which has a domain gap with its training set, dataset for fine-tuning should be collected with as little human efforts as possible.
Therefore it is proposed to gather automatically labeled data based on the uncertainty estimation of the classifier.
Considering the overconfident behavior of deep learning classifiers, a Bayesian neural network is employed to improve the uncertainty estimation.
For easy compatibility with existing neural network architectures, dropout variational inference and scalable Laplace approximation are chosen for this task.
In addition to the naive version, advanced variants of them such as concrete dropout, multiple dropout and ensemble of them are further taken into account.
The original ResNet50 is modified to incorporate these techniques and keep the ability of extracting powerful features at the same time.
Extensive experiments on WRGBD and UniHb dataset are performed to evaluate the performance of the uncertainty estimation of different approaches in terms of different metrics including accuracy, proper scoring rules, calibration metrics, and separability metrics.
The results show that Bayesian neural network can improve the performance of both accuracy and calibration as well as uncertainty estimation when compared with the original ResNet50. 

Secondly, the improved uncertainty estimation is used for collecting automatically labeled dataset, which is used for fine-tuning the model trained on a easily obtainable dataset.
The goal is to obtain a more accurate domain-specific classifier with as little human efforts as possible.
Experiments of this part are performed on both WRGBD/UniHB dataset and original T-LESS/synthetic T-LESS dataset.
During the experiments, it is found out that the balance of data samples in each class has a significant influence on the performance after fine-tuning.
Augmentations are employed to mitigate this problem and the experiments results show that, a more accurate domain-specific can be obtained with much less human efforts, while its performance can reach or even exceed the performance of the classifier obtained with much more human efforts.

Thirdly, the improved uncertainty estimation should be utilized further with a proper probabilistic model.
On the other hand, uncertainty induced by appearances similarity should be handled by modeling the contextual information between objects.
On account of these two points, a conditional random field is employed to further improve the performance by utilizing more information from the output of the Bayesian neural network and capturing the contextual relationship between objects in the same scene.
For the end, experiments are performed to validate this idea but only on the T-LESS dataset because designing pairwise features in WRGBD dataset is non-trivial.
The experimental results show that the CRF can improve the accuracy further by not only making use of the information from better uncertainty estimation but exploiting the contextual relationship between objects.

Although the experimental results show that these approaches can achieve better performance compared to the original version, the problems occurring when constructing approaches and performing experiments should require more attention and efforts towards solving them. There are several main problems listed in the following:
\begin{itemize}
	\item inefficiency in testing with Bayesian neural network: testing each input requires sampling the posterior many times. Different approaches are already available such as network\cite{hinton2015distilling} distillation and parallel computation.  
	
	\item Uncertainty estimation should be defined more clearly and explored with more efforts. For example, the difference of separability metrics and calibration metrics are used to evaluate the uncertainty estimation in literatures\cite{hendrycks2016baseline}\cite{guo2017calibration}. However, they should account for different abilities which should not be summarized with one word. As can be seen in the experiments, well calibrated models may have similar or even worse separability between correct predictions versus miss-classifications or OOD predictions than the badly-calibrated model. 
	
	\item Other approaches to improve uncertainty estimations should be considered. A Bayesian neural network is a principal way for this purpose. But the computation behind that is too high. It is like using a generative model to solve a problem which can be solved by a discriminative model. Maybe there is a more efficient way to achieve this goal such as different post-processing methods \cite{guo2017calibration}. 
	
	\item the way to choose highly confident predictions as automatically labeled data for continuous learning sounds practical and meaningful. However, from the perspective of active learning, the confident predictions contain little information required by the classifier. To train a classifier with a better performance requires a training set with more information. To label predictions with more information (low confidence) sounds more meaningful. Therefore a better technique to combine them should be taken into account. 
	
	\item modeling dependencies between random variables is a promising and natural way to improve the results because the i.i.d. assumption does not hold all the time. However, employing probabilistic graphical models requires hand-crafted edge feature which is non-trivial to have and design. Therefore, graph neural networks which can learn the edge feature based on data is promising to work on.
\end{itemize} 

\section{Conclusion}
\begin{itemize}
	\item Bayesian neural network can improve uncertainty estimation in terms of different evaluation metrics including accuracy, proper scoring rule, calibration and separability between correct predictions versus miss-classifications or OOD predictions, while the ensemble of them can achieve even better performance.
	
	\item Multiple dropout can work better without considering OOD data, while concrete dropout can offer more stable performance on separating correct predictions and miss-classifications.
	
	\item Scalable Laplace approximation with Kronecker-factored approximation can achieve a similar performance as the concrete dropout and multiple dropout, indicating that the performance is highly related to the point estimate obtained during training.
	
	\item Manual efforts in collecting datasets for fine-tuning to enable classifiers to adapt itself to test environments can be reduced with the help of better uncertainty estimation. Nevertheless, the imbalance of a collected dataset has a negative effect on fine-tuning, which can be mitigated by data augmentation and adding little manual labeling.
	
	\item A conditional random field can improve the performance further by utilizing information brought by better uncertainty estimation and exploiting contextual information between objects in the same scene.
	
\end{itemize}


\section{Future work}
There are interesting works related to the approaches used in this work:
\begin{itemize}
	\item Uncertainty distributions of different view points of the object can be checked. On the one hand, to understand the behavior of the neural network better with uncertainty. On the other hand, if the uncertainty can represent the actual discriminability of different view points, this information is useful in down-stream tasks such as optimal view point planing for grasping and so on. 
	\item As mentioned in summary, inefficiency in testing is an important problem. It would be interesting to try a distillation method to decrease the runtime during testing.
	\item Although in this work, dropout variational inference and Laplace approximation are evaluated, the approximation distribution of them seems restrictive and simple. Interesting future work would be to try more complex and expressive approximate posterior distributions such as normalizing flow .
	\item In the experiments of evaluating uncertainty estimation, multiple dropout can achieve a better performance without considering OOD data. The ablation study also shows that multiple dropout can have a better performance. As stated in \cite{kingma2015variational}, covariances between instances increase the variances of estimating derivatives of the variational parameters. One way to improve the performance of the multiple dropout would be to decrease the variance of estimating variational parameters by sampling masks for each instance separately because there are more parameters than concrete dropout. 
\end{itemize}