\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{koller2009probabilistic}
\citation{der2009aleatory,senge2014reliable,kendall2017uncertainties}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is uncertainty?}{1}{section.1.1}\protected@file@percent }
\citation{guo2017calibration}
\citation{amodei2016concrete}
\citation{mcallister2017concrete}
\citation{leibig2017leveraging}
\citation{denker1991transforming}
\citation{kendall2017multi}
\citation{hendrycks2016baseline}
\citation{kurakin2016adversarial}
\citation{feinman2017detecting}
\citation{gal2017deep}
\citation{blundell2015weight}
\citation{osband2016deep}
\citation{gal2016improving}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why do we need uncertainty?}{2}{section.1.2}\protected@file@percent }
\citation{kendall2016modelling}
\citation{feng2018towards}
\citation{krahenbuhl2011efficient}
\citation{sutton2012introduction}
\citation{lin2016efficient}
\citation{guo2017calibration}
\citation{amodei2016concrete}
\citation{mcallister2017concrete}
\citation{leibig2017leveraging}
\citation{denker1991transforming}
\citation{kendall2017multi}
\citation{hendrycks2016baseline}
\citation{kurakin2016adversarial,feinman2017detecting}
\@writefile{tdo}{\contentsline {todo}{this sentence is not clear to me! The uncertainty by itself exists in every (classifier) model. So arguing, that with the uncertainty the overconfidence can be reduced is not 100\% correct. Rather that the extraction and understanding and then the improvement of the uncertainty can reduce the overconfidence. What do you think?}{3}{section*.3}\protected@file@percent }
\citation{gal2017deep}
\citation{blundell2015weight}
\citation{osband2016deep}
\citation{gal2016improving}
\@writefile{tdo}{\contentsline {todo}{in a objective work you write it is instead of it'S ;) check at the end if you have no it's in your work ;P}{4}{section*.4}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{well, you are already talking about misclassification above right? so leave it out here?}{4}{section*.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{I would cite more references together like I did it here. What do you think?}{4}{section*.6}\protected@file@percent }
\citation{kendall2016modelling}
\citation{feng2018towards}
\citation{krahenbuhl2011efficient}
\citation{sutton2012introduction}
\citation{lin2016efficient}
\@writefile{tdo}{\contentsline {todo}{the colored part does not make sense. perhaps something is missing in the sentence?!}{5}{section*.7}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{you do not want to use abbreviations in your work?! check the glossary package ;)}{5}{section*.8}\protected@file@percent }
\citation{liang2017enhancing}
\citation{devries2018learning}
\citation{lee2017training}
\citation{mackay1992practical}
\citation{neal2012bayesian}
\citation{osband2016deep}
\citation{lakshminarayanan2017simple}
\citation{smith2018understanding}
\citation{neal2012bayesian}
\citation{welling2011bayesian}
\citation{balan2015bayesian}
\citation{wang2018adversarial}
\citation{hinton1993keeping}
\citation{graves2011practical}
\citation{blundell2015weight}
\citation{kingma2013auto}
\citation{hernandez2015probabilistic}
\citation{minka2001expectation}
\citation{gal2016dropout}
\citation{kingma2015variational}
\citation{louizos2016structured}
\citation{sun2017learning}
\citation{zhang2017noisy}
\citation{louizos2017multiplicative}
\citation{hinton1993keeping}
\citation{graves2011practical}
\citation{blundell2015weight}
\citation{kingma2013auto}
\citation{hernandez2015probabilistic}
\citation{minka2001expectation}
\citation{gal2016dropout}
\citation{kingma2015variational}
\citation{louizos2016structured}
\citation{sun2017learning}
\citation{zhang2017noisy}
\citation{louizos2017multiplicative}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}How can we obtain and handle uncertainty in deep learning?}{6}{section.1.3}\protected@file@percent }
\citation{mackay1992practical}
\citation{ritter2018scalable}
\citation{gal2016dropout}
\citation{ritter2018scalable}
\citation{kendall2017uncertainties}
\citation{lafferty2001conditional}
\citation{ladicky2010graph}
\citation{rasiwasia2009holistic}
\citation{galleguillos2008object}
\citation{rabinovich2007objects}
\citation{he2016deep}
\citation{he2016deep}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Contributions and Structure}{8}{section.1.4}\protected@file@percent }
\@setckpt{Introduction}{
\setcounter{page}{11}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{StandardModuleDepth}{0}
\setcounter{AM@survey}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{6}
\setcounter{NAT@ctr}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{4}
\setcounter{@todonotes@numberoftodonotes}{6}
\setcounter{section@level}{1}
}
